{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "782f7c6f",
      "metadata": {
        "id": "782f7c6f"
      },
      "source": [
        "# Model Validation\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Load the trained NER model and tokenizer from the `model/` directory.\n",
        "2. Load and preprocess the validation data from `data/validation.conll`.\n",
        "3. Run predictions on the validation set.\n",
        "4. Evaluate the model's performance using standard NER metrics.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5_KW6JCbKYn",
        "outputId": "f6594196-7e55-499d-99b4-b67e6f4c2c83"
      },
      "id": "K5_KW6JCbKYn",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tepQliRJbdUM",
        "outputId": "4b363e31-e96b-4a57-ad77-b0f87d0d5b81"
      },
      "id": "tepQliRJbdUM",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=3df1324aff632f02c5fbc62398a623017fa957e46d200e781d071cad1aad592f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3c261ffc",
      "metadata": {
        "id": "3c261ffc"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from seqeval.metrics import classification_report, f1_score, accuracy_score\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b58473fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58473fa",
        "outputId": "9851969e-ee78-404a-ceaf-1e9564aa93ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForTokenClassification(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=35, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Load the trained model and tokenizer\n",
        "model_dir = '/content/drive/MyDrive/arner'  # path to the model directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "model.eval()  # set model to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ba958a53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba958a53",
        "outputId": "655cf5a0-c449-44f1-bd24-90375ec69746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 35\n"
          ]
        }
      ],
      "source": [
        "# Get label mappings from the model config\n",
        "label2id = model.config.label2id  # label name -> id\n",
        "id2label = model.config.id2label  # id (as int or str) -> label name\n",
        "num_labels = len(label2id)\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ReadConll(filename):\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(filename,\n",
        "                    sep = ' ', header = None, keep_default_na = False,\n",
        "                    names = ['words','labels',\"blank\"],\n",
        "                    quoting = 3,\n",
        "                     skip_blank_lines = False,\n",
        "                     encoding=\"utf8\")\n",
        "    df = df[~df['words'].astype(str).str.startswith('#')] # Remove the -DOCSTART- header\n",
        "    df['sentence_id'] = (df.words == '').cumsum()\n",
        "    print(df[df.words != ''])\n",
        "    return df[df.words != '']\n",
        "\n",
        "def ClsReportNerModel(test_conll_path, tokenizer, model, device):\n",
        "    !pip install seqeval\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    test = ReadConll(test_conll_path)\n",
        "    sents_tokens_list, truth_list = [],[]\n",
        "    model = model.to(device)\n",
        "    for i in test.sentence_id.unique():\n",
        "        sents_tokens_list.append(list(test[test.sentence_id == i].words))\n",
        "        truth_list.append(list(test[test.sentence_id == i].labels))\n",
        "    tokens,preds,truths= [],[],[]\n",
        "    for sentence_idx, sent_token_list in enumerate(sents_tokens_list):\n",
        "        print(f\"Processing sentence {sentence_idx+1}/{len(sents_tokens_list)}\")\n",
        "\n",
        "        model_inputs = tokenizer(sent_token_list, is_split_into_words = True, truncation=True,\n",
        "                                        padding=False, max_length=256, return_tensors=\"pt\").to(device)\n",
        "        word_ids = model_inputs.word_ids() # sub tokenlar sent_token_list deki hangi idxteki tokena ait\n",
        "        # ornek word_ids = [None, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15, None]\n",
        "        outputs = model(**model_inputs)\n",
        "        predictions = outputs.logits.argmax(dim=-1).tolist()[0]\n",
        "        idx = 1\n",
        "        while idx < len(word_ids)-1: # sondaki None icin islem yapmamak icin -1 yapildi\n",
        "            word_id1 = word_ids[idx]\n",
        "            word_id2 = word_ids[idx + 1]\n",
        "            label = model.config.id2label[predictions[idx]]\n",
        "            if word_id1 == word_id2:\n",
        "                while word_id1 == word_ids[idx]:\n",
        "                    idx +=1\n",
        "                idx -=1\n",
        "\n",
        "            token = sent_token_list[word_ids[idx]]\n",
        "            truth = truth_list[sentence_idx][word_ids[idx]]\n",
        "            tokens.append(token)\n",
        "            preds.append(label)\n",
        "            truths.append(truth)\n",
        "            idx +=1\n",
        "    from seqeval.metrics import classification_report\n",
        "    print(classification_report([truths], [preds], digits = 4, mode = 'strict'))\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(classification_report(truths, preds, digits = 4))\n"
      ],
      "metadata": {
        "id": "FN4ccyM9j10f"
      },
      "id": "FN4ccyM9j10f",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ClsReportNerModel(\"/content/drive/MyDrive/arner/validation.conll\", tokenizer, model, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceQoVxyuj729",
        "outputId": "f3d2f5df-6e87-4610-8ea8-0bc23531e6e7"
      },
      "id": "ceQoVxyuj729",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "                      words       labels blank  sentence_id\n",
            "1                        Ma            O                  0\n",
            "2                      mère            O                  0\n",
            "3                    Astrit  B-GIVENNAME                  0\n",
            "4                      Nani            O                  0\n",
            "5                      Kofi    B-SURNAME                  0\n",
            "...                     ...          ...   ...          ...\n",
            "1644052                 876            O              82930\n",
            "1644053                  19            O              82930\n",
            "1644054                  et            O              82930\n",
            "1644055                 les            O              82930\n",
            "1644056  31-80-113-166-197.     B-TAXNUM              82930\n",
            "\n",
            "[1478169 rows x 4 columns]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "             AGE     0.9670    0.9870    0.9769      4217\n",
            "     BUILDINGNUM     0.9791    0.9738    0.9764      7830\n",
            "            CITY     0.9618    0.9715    0.9666     13260\n",
            "CREDITCARDNUMBER     0.9795    0.9869    0.9832      1837\n",
            "            DATE     0.9993    0.9996    0.9995     10101\n",
            "DRIVERLICENSENUM     0.9109    0.8052    0.8548      1663\n",
            "           EMAIL     0.9998    0.9998    0.9998      9994\n",
            "          GENDER     0.7854    0.8763    0.8284      1520\n",
            "       GIVENNAME     0.9593    0.9740    0.9666     62085\n",
            "       IDCARDNUM     0.8943    0.9426    0.9178      6782\n",
            "     PASSPORTNUM     0.9042    0.8525    0.8776      3133\n",
            "             SEX     0.8840    0.8004    0.8401      1904\n",
            "       SOCIALNUM     0.8714    0.9442    0.9063      1737\n",
            "          STREET     0.9814    0.9708    0.9761      8866\n",
            "         SURNAME     0.8609    0.8308    0.8456     24001\n",
            "          TAXNUM     0.9768    0.9118    0.9432      2121\n",
            "    TELEPHONENUM     0.9969    0.9978    0.9973     13355\n",
            "            TIME     0.9993    0.9999    0.9996     10637\n",
            "           TITLE     0.9877    0.9936    0.9906      7019\n",
            "         ZIPCODE     0.9678    0.9719    0.9698      3243\n",
            "\n",
            "       micro avg     0.9536    0.9550    0.9543    195305\n",
            "       macro avg     0.9433    0.9395    0.9408    195305\n",
            "    weighted avg     0.9533    0.9550    0.9540    195305\n",
            "\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "             B-AGE     0.9670    0.9870    0.9769      4217\n",
            "     B-BUILDINGNUM     0.9792    0.9739    0.9766      7830\n",
            "            B-CITY     0.9644    0.9741    0.9692     13260\n",
            "B-CREDITCARDNUMBER     0.9795    0.9869    0.9832      1837\n",
            "            B-DATE     0.9994    0.9997    0.9996     10101\n",
            "B-DRIVERLICENSENUM     0.9116    0.8058    0.8554      1663\n",
            "           B-EMAIL     0.9998    0.9998    0.9998      9994\n",
            "          B-GENDER     0.7854    0.8763    0.8284      1520\n",
            "       B-GIVENNAME     0.9745    0.9894    0.9819     62085\n",
            "       B-IDCARDNUM     0.8943    0.9426    0.9178      6782\n",
            "     B-PASSPORTNUM     0.9042    0.8525    0.8776      3133\n",
            "             B-SEX     0.8840    0.8004    0.8401      1904\n",
            "       B-SOCIALNUM     0.8730    0.9459    0.9080      1737\n",
            "          B-STREET     0.9840    0.9734    0.9787      8866\n",
            "         B-SURNAME     0.8622    0.8322    0.8469     24001\n",
            "          B-TAXNUM     0.9773    0.9123    0.9437      2121\n",
            "    B-TELEPHONENUM     0.9983    0.9991    0.9987     13355\n",
            "            B-TIME     0.9993    0.9999    0.9996     10637\n",
            "           B-TITLE     0.9877    0.9936    0.9906      7019\n",
            "         B-ZIPCODE     0.9681    0.9722    0.9702      3243\n",
            "     I-BUILDINGNUM     0.7500    1.0000    0.8571        12\n",
            "            I-CITY     0.9730    0.9803    0.9766      2386\n",
            "            I-DATE     0.9997    0.9993    0.9995      3072\n",
            "I-DRIVERLICENSENUM     0.9936    0.9873    0.9905       158\n",
            "           I-EMAIL     1.0000    1.0000    1.0000        42\n",
            "       I-GIVENNAME     0.9207    0.9517    0.9359      7951\n",
            "       I-SOCIALNUM     1.0000    0.9719    0.9858       285\n",
            "          I-STREET     0.9777    0.9806    0.9791      2418\n",
            "         I-SURNAME     0.9303    0.8746    0.9016      5009\n",
            "          I-TAXNUM     0.9832    0.9915    0.9873       236\n",
            "    I-TELEPHONENUM     0.9946    0.9985    0.9966      5363\n",
            "            I-TIME     0.9964    1.0000    0.9982       546\n",
            "         I-ZIPCODE     0.9570    1.0000    0.9780       178\n",
            "                 O     0.9983    0.9981    0.9982   1255145\n",
            "\n",
            "          accuracy                         0.9924   1478106\n",
            "         macro avg     0.9520    0.9574    0.9537   1478106\n",
            "      weighted avg     0.9924    0.9924    0.9923   1478106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d03b223d"
      },
      "source": [
        "## Validation Output Assessment\n",
        "\n",
        "Based on the validation output, here's an assessment of the model's performance:\n",
        "\n",
        "The output provides two classification reports: one using `seqeval` metrics (strict mode) and another using `sklearn` metrics.\n",
        "\n",
        "**Seqeval Classification Report (Strict Mode):**\n",
        "\n",
        "This report provides precision, recall, and F1-score for each individual named entity (B- and I- tags) and also overall micro, macro, and weighted averages.\n",
        "\n",
        "*   **Overall Performance:** The micro, macro, and weighted averages show strong performance across the board, with F1-scores around 0.95. This indicates that the model is generally performing well in identifying and classifying named entities.\n",
        "*   **Entity-Specific Performance:** Most entity types have high precision, recall, and F1-scores (above 0.90), suggesting the model is effective at recognizing these entities. Some entities like `AGE`, `DATE`, `EMAIL`, `TELEPHONENUM`, and `TIME` have near-perfect scores.\n",
        "*   **Lower Performing Entities:** Entities like `DRIVERLICENSENUM`, `SEX`, and `SOCIALNUM` have slightly lower F1-scores (though still respectable, mostly above 0.80). This might indicate that these entity types are more challenging for the model to identify accurately, potentially due to less training data or more complex patterns.\n",
        "*   **\"O\" (Outside) Tag:** The \"O\" tag, representing tokens that are not part of any named entity, has very high precision, recall, and F1-score (around 0.998), which is expected and good.\n",
        "\n",
        "**Sklearn Classification Report:**\n",
        "\n",
        "This report provides precision, recall, and F1-score for the unique labels in the dataset, which includes both the B- and I- tags merged into a single category for each entity type (e.g., \"AGE\" instead of \"B-AGE\" and \"I-AGE\"). It also includes the \"O\" tag.\n",
        "\n",
        "*   **Overall Performance:** Similar to the seqeval report, the overall averages are very high (around 0.99 for accuracy, and 0.95 for macro and weighted averages of precision, recall, and f1-score), indicating strong performance.\n",
        "*   **Entity-Specific Performance:** This report confirms the trends seen in the seqeval report, with most entity types having excellent scores. The entities with slightly lower scores in the seqeval report (like `DRIVERLICENSENUM`, `SEX`, and `SOCIALNUM`) still show lower F1-scores here compared to the top-performing entities.\n",
        "\n",
        "**Overall Assessment:**\n",
        "\n",
        "The model demonstrates strong performance on the validation set. The high F1-scores across most entity types indicate that the model is effectively identifying and classifying named entities. While some entity types have slightly lower scores, the overall performance is impressive. The slight differences between the seqeval and sklearn reports are due to the different evaluation methodologies (seqeval's strict mode is more sensitive to boundary errors).\n",
        "\n",
        "To further improve the model, you could consider:\n",
        "\n",
        "*   Investigating the entity types with lower scores to understand why they are more challenging.\n",
        "*   Potentially augmenting the training data for these lower-performing entity types.\n",
        "*   Experimenting with different model architectures or hyperparameters.\n",
        "*   Analyzing specific examples where the model made incorrect predictions to identify patterns in errors."
      ],
      "id": "d03b223d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (pii)",
      "language": "python",
      "name": "pii"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}